{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b3871974",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import urllib.request\n",
    "import csv\n",
    "import urllib.request, urllib.parse, urllib.error\n",
    "from bs4 import BeautifulSoup\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ce709b3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "headers = {'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_13_6) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/70.0.3538.77 Safari/537.36'}\n",
    "\n",
    "req = urllib.request.Request('https://www.metacritic.com/browse/movies/score/metascore/all/filtered?sort=desc', headers = headers)\n",
    "fhand = urllib.request.urlopen(req)\n",
    "print(fhand)\n",
    "soup = BeautifulSoup(fhand,'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dc56ae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperlinks = soup.find_all('a',attrs = {'class':'title'})\n",
    "for i in hyperlinks:\n",
    "    print(i.get_text())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eb17c2df",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = []\n",
    "for i in hyperlinks:\n",
    "    url.append('https://www.metacritic.com/'+i.get('href'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47c29bce",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in url:\n",
    "    print(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1ec77d22",
   "metadata": {},
   "outputs": [],
   "source": [
    "title = [] ## Get all the title to an empty list\n",
    "all_url = [] ## Get all the url \n",
    "all_hyperlink = []\n",
    "for i in range(5):\n",
    "    req = urllib.request.Request('https://www.metacritic.com/browse/movies/score/metascore/all/filtered?sort=desc&page='+str(i), headers = headers)\n",
    "    fhand = urllib.request.urlopen(req)\n",
    "    soup = BeautifulSoup(fhand,'html.parser')\n",
    "    hyperlink = soup.find_all('a',attrs = {'class':'title'})\n",
    "    all_hyperlink.extend(hyperlink)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "db0966d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in all_hyperlink:\n",
    "    all_url.append('https://www.metacritic.com/'+i.get('href'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8dcf319b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['https://www.metacritic.com//movie/rear-window', 'https://www.metacritic.com//movie/casablanca', 'https://www.metacritic.com//movie/boyhood']\n"
     ]
    }
   ],
   "source": [
    "print(all_url[2:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e36c4534",
   "metadata": {},
   "outputs": [],
   "source": [
    "req = urllib.request.Request('https://www.metacritic.com/movie/the-godfather', headers = headers)\n",
    "fhand = urllib.request.urlopen(req)\n",
    "soup = BeautifulSoup(fhand, 'html.parser')\n",
    "title = soup.find_all('div',attrs = {'class':'product_page_title oswald'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "840c48f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "title_name = title[0].get_text().strip().replace('\\n',' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73aacfb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(title_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2bf9794c",
   "metadata": {},
   "outputs": [],
   "source": [
    "director = [] # Create an empty list \n",
    "# Create a loop that loop thru each url , and html and get all the directors name and save it all into director list\n",
    "movie = {}\n",
    "\n",
    "genres = []\n",
    "\n",
    "#####\n",
    "for i in all_url:\n",
    "    req = urllib.request.Request(i, headers = headers )\n",
    "    fhand = urllib.request.urlopen(req)\n",
    "    soup = BeautifulSoup(fhand, 'html.parser')\n",
    "    ### Getting Title Name\n",
    "    title = soup.find_all('div',attrs = {'class':'product_page_title oswald'})\n",
    "    title_name = title[0].get_text().strip().replace('\\n',' ')\n",
    "    #### Getting Directors name and append it into Director empty list \n",
    "    director_div = soup.find('div',attrs ={'class':'director'} )\n",
    "    director_link = director_div.find_all('a')\n",
    "    dir_temp_list = []\n",
    "    for j in director_link:\n",
    "        dir_temp_list.append(j.get_text())\n",
    "    director_tuple = tuple(dir_temp_list)\n",
    "    ##### Getting Genres and append it into Genres list \n",
    "    genre_div = soup.find('div' , attrs = {'class':'genres'})\n",
    "    genre_list = genre_div.find_all('span')\n",
    "    tem_list = []\n",
    "    for k in genre_list:\n",
    "        tem_list.append(k.get_text())\n",
    "    genres.append(tem_list[2:])\n",
    " \n",
    " ##Create a dictionary\n",
    "    sub_dict = {}\n",
    "    sub_dict[director_tuple] = tem_list[2:]\n",
    "##Create a movie dictionary \n",
    "    movie[title_name] = sub_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "85e96b90",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fhandle = open('movie_list.csv',mode ='w',newline = '') \n",
    "movie_writer = csv.writer(fhandle) \n",
    "for key1,value1 in movie.items():\n",
    "    for key2,value2 in value1.items():\n",
    "        movie_writer.writerow([key1,', '.join(list(key2)),', '.join(value2)])\n",
    "fhandle.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "3c3dbef192cb335f83a5dd9e9161a69cadeaf5d6631cb9cd12bddb603fc54a22"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
